\include{settings}

\begin{document}

\include{titlepage}

\tableofcontents
\listoffigures
\newpage

\section{Цели работы}

Изучение архитектуры персептрона и специальных функций для создания персептрона, настройки его весов и смещений и адаптации, ознакомление с демонстрационными примерами, а так­же приобретение навыков построения и обучения персептронов для различных областей применения.

\section{Классификация 2 линейно-неразделимых классов}

\subsection{Набор входных и желаемых образов}

%1. Сформируйте набор входных и желаемых выходных образов ( “0” – класс 1, “X” – класс 2. Постройте график и нанесите на него эти точки.

Сформируем набор входных и желаемых выходных образов для двух линейно-неразделимых классов. На рис. \ref{fig:1_1} входной набор изоражен на графике, при этом класс \verb+0+ отмечен синими кругами, а класс \verb+1+ красными крестиками.

\begin{figure}[H]
\begin{center}
	\includegraphics[scale=1.1]{1_1}
	\caption{Набор выходных и желаемых выходных образов}
	\label{fig:1_1}
\end{center}
\end{figure}

\subsection{Аналитическое решение}

%2. Для заданного варианта сформируйте собственный вариант решения задачи без ошибок и реализуйте его аналитически вначале математически с помощью формул, а затем с помощью 2-х или 3-х слойного персептрона (для этого вначале с помощью кусочно-линейной аппроксимации задайте функции, определяющие принадлежность к классу 1 и 2). 

Разделим входное пространство на 4 выпуклые области, ограниченные прямыми:
\begin{equation*}
	\begin{cases}
		>1\\
		>2
	\end{cases}
	\hspace{1cm}
	\begin{cases}
		<3\\
		>4\\
		>5
	\end{cases}
	\hspace{1cm}
	\begin{cases}
		<3\\
		>4\\
		<6
	\end{cases}
	\hspace{1cm}
	\begin{cases}
		<6\\
		<7
	\end{cases}
\end{equation*}

\begin{figure}[H]
\begin{center}
	\includegraphics[scale=1.1]{1_2_1}
	\caption{Разбие с помощью множества прямых}
	\label{fig:rs}
\end{center}
\end{figure}

Составим уравнения прямых для каждого слоя:

\paragraph{Первый слой}
\begin{enumerate}
	\item $x_1 - 3.5 = 0 \rightarrow y_{11}$
	\item $x_2 - 1.5 = 0 \rightarrow y_{12}$
	\item $-x_2 + 3.5 = 0 \rightarrow y_{13}$
	\item $x_1 - 1.5 = 0 \rightarrow y_{14}$
	\item $x_2 - 2.5 = 0 \rightarrow y_{15}$
	\item $-x_1 + 2.5 = 0 \rightarrow y_{16}$
	\item $-x_2 + 1.5 = 0 \rightarrow y_{17}$
\end{enumerate}

\paragraph{Второй слой}
\begin{enumerate}
	\item $y_{11} + y_{12} - 1.5 = 0 \rightarrow y_{21}$
	\item $y_{13} + y_{14} + y_{15} - 2.5 = 0 \rightarrow y_{22}$
	\item $y_{13} + y_{14} + y_{16} - 2.5 = 0 \rightarrow y_{23}$
	\item $y_{16} + y_{17} - 1.5 = 0 \rightarrow y_{24}$
\end{enumerate}

\paragraph{Третий слой}
\begin{enumerate}
	\item $y = y_{21} + y_{22} + y_{23} + y_{24} - 0.5$
\end{enumerate}

\begin{figure}[H]
\begin{center}
	\includegraphics[width=\textwidth]{1_2_2}
	\caption{Аналитическое разбиение}
	\label{fig:rs}
\end{center}
\end{figure}

\subsection{Схема сети}

%3. Сгенерируйте схему командой gensim (net), проанализируйте ее и приведите в отчет.

На рис. \ref{fig:1_3} изображена схема, полученная при помощи команды \verb+gensim+.

\begin{figure}[H]
\begin{center}
	\includegraphics[width=0.7\textwidth]{1_3}
	\caption{Схема сети}
	\label{fig:1_3}
\end{center}
\end{figure}

\subsection{Проверка аналитического разбиения}

%4. Проверьте полученные функции в заданных точках, а также в близлежащих точках.

На рис. \ref{fig:1_4} изображено разбиение случайных точек входного пространства на классы.

\begin{figure}[H]
\begin{center}
	\includegraphics[width=0.8\textwidth]{1_4}
	\caption{Проверка в случайных точках входного пространства}
	\label{fig:1_4}
\end{center}
\end{figure}

\subsection{Решение с помощью 1-слойного персептрона}

%5. Попытайтесь решить задачу распознавания путем обучения 1-слойного персептрона на множестве входных примеров. Проанализируйте полученный результат.

Попробуем решить задачу распознование путем обучения 1-слойного персептрона. На рис. \ref{fig:1_5_1} изображено разбиение на 2 класса.

\begin{figure}[H]
\begin{center}
	\includegraphics[width=0.8\textwidth]{1_5_1}
	\caption{Разбиение с помощью 1-слойного персептрона}
	\label{fig:1_5_1}
\end{center}
\end{figure}

На рис. \ref{fig:1_5_2} изображено значние ошибки в процессе обучения. Видно что оно колеблется, следовательно процесс обучения не сходится.

\begin{figure}[H]
\begin{center}
	\includegraphics[width=0.8\textwidth]{1_5_2}
	\caption{Значние ошибки в процессе обучения}
	\label{fig:1_5_2}
\end{center}
\end{figure}

\section{Линейная функция}

\subsection{СДНФ}

Задана логическая функция:

\begin{equation*}
\begin{cases}
	y = f(X)\\
	X = [x_1, x_2, x_3, x_4, x_5]\\
	x_i \in \{0, 1\}\\
	y_i \in \{0, 1\}\\
	y(X) = 0, X \in \{ 5, 10, 13, 15, 16, 21, 24, 26 \}
\end{cases}
\end{equation*}

\begin{align*}
&\overline{x_1}\ \overline{x_2}\ x_3\ \overline{x_4}\ x_5 +
\overline{x_1}\ x_2\ \overline{x_3}\ x_4\ \overline{x_5} +
\overline{x_1}\ x_2\ x_3\ \overline{x_4}\ x_5 +
\overline{x_1}\ x_2\ x_3\ x_4\ x_5\ + \\
&x_1\ \overline{x_2}\ \overline{x_3}\ \overline{x_4}\ \overline{x_5} +
x_1\ \overline{x_2}\ x_3\ \overline{x_4}\ x_5 +
x_1\ x_2\ \overline{x_3}\ \overline{x_4}\ \overline{x_5} +
x_1\ x_2\ \overline{x_3}\ x_4\ \overline{x_5}
\end{align*}

%1.  Запишите выражение для вашей ЛФ в форме СДНФ.

\subsection{СДНФ в форме 2-слойного персептрона}

%2. Реализуйте полученную СДНФ в форме 2-слойного персептрона (net) в Matlab.

Логическая функция была реализована в форме 2-слойного персептрона. 

\subsection{Схема сети}

%3. Сгенерируйте схему командой gensim (net), проанализируйте ее и приведите в отчет.


На рис. \ref{fig:2_3} изображена схема, полученная при помощи команды \verb+gensim+.

\begin{figure}[H]
\begin{center}
	\includegraphics[width=0.8\textwidth]{2_3}
	\caption{Схема сети}
	\label{fig:2_3}
\end{center}
\end{figure}

\subsection{Проверка работы}

%4. Проверьте правильность работы полученной НС по таблице истинности.

На рис. \ref{fig:2_4} изображены выходные значения для 32 входных примеров. Выходные значения нейронной сети полностью совпали с таблицей истинности.

\begin{figure}[H]
\begin{center}
	\includegraphics[width=1\textwidth]{2_4}
	\caption{Выходные значения}
	\label{fig:2_4}
\end{center}
\end{figure}

\subsection{1-слоный персептрон}

%5. Попробуйте обучить однослойный персептрон на Вашей функции, используя в качестве обучающей выборки фрагменты таблицы истинности. Проанализируйте результаты и посчитайте среднюю ошибку.	

Попробуем решить задачу путем обучения 1-слойного персептрона. На рис. \ref{fig:2_5} изображено значние ошибки в процессе обучения. Видно что оно колеблется, следовательно процесс обучения не сходится.

\begin{figure}[H]
\begin{center}
	\includegraphics[width=0.8\textwidth]{2_5}
	\caption{Значние ошибки в процессе обучения}
	\label{fig:2_5}
\end{center}
\end{figure}

\section{Классификация 2 класссов}

\subsection{Набор входных и желаемых образов}

Сформируем набор входных и желаемых выходных образов для двух линейно-неразделимых классов. На рис. \ref{fig:3_1} входной набор изоражен на графике, при этом класс \verb+1+ выделен синей областью.

\begin{figure}[H]
\begin{center}
	\includegraphics[scale=1]{3_1}
	\caption{Набор выходных и желаемых выходных образов}
	\label{fig:3_1}
\end{center}
\end{figure}

\subsection{Аналитическое решение}

%1. Запишите аналитическое выражение для функции, реализующей Ваше разбиение плоскости на 2 класса. Постройте график функции и разбиение плоскости на классы.
%2. Реализуйте полученную функцию в форме 2-х или 3-х слойного персептрона net в Matlab. 

\paragraph{Первый слой}
\begin{enumerate}
	\item $x_1 - x_2 + 1.5 = 0 \rightarrow y_{11}$
	\item $-x_1 + x_2 + 0.5 = 0 \rightarrow y_{12}$
	\item $-x_1 + x_2 - 0.5 = 0 \rightarrow y_{13}$
	\item $x_1 + x_2 - 0.5 = 0 \rightarrow y_{14}$
	\item $-x_1 + 0.4 = 0 \rightarrow y_{15}$
	\item $x_2 - 0.6 = 0 \rightarrow y_{16}$
	\item $x_1 - 0.6 = 0 \rightarrow y_{17}$
	\item $-x_2 + 0.4 = 0 \rightarrow y_{18}$
\end{enumerate}

\paragraph{Второй слой}
\begin{enumerate}
	\item $y_{11} + y_{12} + y_{13} + y_{14} - 3.5 = 0 \rightarrow y_{21}$
	\item $y_{15} + y_{16} + y_{17} + y_{18} - 3.5 = 0 \rightarrow y_{22}$
\end{enumerate}

\paragraph{Третий слой}
\begin{enumerate}
	\item $y = y_{21} - 2 y_{22} - 0.5$
\end{enumerate}

\subsection{Схема сети}

%3. Сгенерируйте схему командой gensim (net), проанализируйте ее и приведите в отчет.

На рис. \ref{fig:3_2} изображена схема, полученная при помощи команды \verb+gensim+.

\begin{figure}[H]
\begin{center}
	\includegraphics[width=0.8\textwidth]{3_2}
	\caption{Схема сети}
	\label{fig:3_2}
\end{center}
\end{figure}

\subsection{Проверка аналитического решения}

%4. Проверьте правильность работы полученной НС путем построения разбиения плоскости на классы, которое реализует персептрон.

На рис. \ref{fig:3_3} изображено разбиение случайных точек входного пространства на классы.

\begin{figure}[H]
\begin{center}
	\includegraphics[width=0.8\textwidth]{3_3}
	\caption{Проверка в случайных точках входного пространства}
	\label{fig:3_3}
\end{center}
\end{figure}

\subsection{Решение с помощью 1-слойного персептрона}

%5. Попытайтесь решить задачу распознавания путем обучения 1-слойного персептрона на множестве входных примеров. Для этого вначале сформируйте обучающую выборку необходимого объема. 

Попробуем решить задачу распознование путем обучения 1-слойного персептрона. На рис. \ref{fig:3_4_1} изображено разбиение на 2 класса.

\begin{figure}[H]
\begin{center}
	\includegraphics[width=0.8\textwidth]{3_4_1}
	\caption{Разбиение с помощью 1-слойного персептрона}
	\label{fig:3_4_1}
\end{center}
\end{figure}

На рис. \ref{fig:3_4_2} изображено значние ошибки в процессе обучения. Видно что оно колеблется, следовательно процесс обучения не сходится.

\begin{figure}[H]
\begin{center}
	\includegraphics[width=0.8\textwidth]{3_4_2}
	\caption{Значние ошибки в процессе обучения}
	\label{fig:3_4_2}
\end{center}
\end{figure}

%\subsection{Анализ результатов}

%6. После обучения посчитайте среднюю ошибку, проанализируйте результаты – какую функцию реализует обученная сеть. 

\section{Классификация $N$ классов}

\subsection{Набор входных и желаемых образов}

Сформируем набор входных и желаемых выходных образов для двух линейно-неразделимых классов. На рис. \ref{fig:4_1} входной набор изоражен на графике, при этом каждый класс выделен свои цветом.

\begin{figure}[H]
\begin{center}
	\includegraphics[scale=1]{4_1}
	\caption{Набор выходных и желаемых выходных образов}
	\label{fig:4_1}
\end{center}
\end{figure}

\subsection{Аналитическое решение}

%1. Запишите аналитическое выражение для функции, реализующей Ваше разбиение плоскости на m классов. Постройте график с разбиением плоскости на m классов.
%2. Реализуйте полученную функцию в форме 2-х или 3-х слойного персептрона net в Matlab. 

\paragraph{Первый слой}
\begin{enumerate}
	\item $-2 x_1 + x_2 = 0 \rightarrow y_{1,1}$
	\item $-0.5 x_1 - x_2 + 1 = 0 \rightarrow y_{1,2}$\\
	\item $0.5 x_1 + x_2 - 1 = 0 \rightarrow y_{1,3}$
	\item $-2 x_1 + x_2 + 1 = 0 \rightarrow y_{1,4}$\\
	\item $2 x_1 - x_2 - 1 = 0 \rightarrow y_{1,5}$
	\item $0.5 x_1 + x_2 - 0.5 = 0 \rightarrow y_{1,6}$\\
	\item $-0.5 x_1 - x_2 + 0.5 = 0 \rightarrow y_{1,7}$
	\item $2 x_1 - x_2 = 0 \rightarrow y_{1,8}$\\
	\item $-3 x_1 - x_2 + 2 = 0 \rightarrow y_{1,9}$
	\item $-\frac{1}{3} x_1 + x_2 - \frac{1}{3} = 0 \rightarrow y_{1,10}$\\
	\item $3 x_1 + x_2 - 2 = 0 \rightarrow y_{1,11}$\\
	\item $\frac{1}{3} x_1 - x_2 + \frac{1}{3} = 0 \rightarrow y_{1,13}$
	\item $-2 x_1 + x_2 + 1 = 0 \rightarrow y_{1,12}$\\
\end{enumerate}

\paragraph{Второй слой}
\begin{enumerate}
	\item 
	%\item $y_{11} + y_{12} + y_{13} + y_{14} - 3.5 = 0 \rightarrow y_{21}$
	%\item $y_{15} + y_{16} + y_{17} + y_{18} - 3.5 = 0 \rightarrow y_{22}$
\end{enumerate}

\paragraph{Третий слой}
\begin{enumerate}
	\item
%	\item $y = y_{21} - 2 y_{22} - 0.5$
\end{enumerate}

\subsection{Схема сети}

%3. Сгенерируйте схему командой gensim (net), проанализируйте ее и приведите в отчет.

\subsection{Проверка аналитического решения}

%4. Проверьте правильность работы полученной НС путем построения разбиения плоскости на классы, которое реализует персептрон.

\end{document}